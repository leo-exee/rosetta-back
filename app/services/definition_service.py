import json
import logging
import os
import random
import time

import requests

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DefinitionFetcher:
    def __init__(self, delay_range: tuple = (0.5, 2.0)):
        """
        Initialise le r√©cup√©rateur de d√©finitions
        Args:
            delay_range: D√©lai al√©atoire entre les requ√™tes (min, max) en secondes
        """
        self.delay_range = delay_range
        self.session = requests.Session()

        # APIs de dictionnaires disponibles
        self.apis = {
            "dictionaryapi": "https://api.dictionaryapi.dev/api/v2/entries/en/",
            "wordnik": "https://api.wordnik.com/v4/word.json/",  # N√©cessite une cl√© API
        }

        # Statistiques
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "cached_definitions": 0,
        }

        # Cache simple pour √©viter les requ√™tes r√©p√©t√©es
        self.cache = {}

    def fetch_definition_dictionaryapi(self, word: str) -> dict | None:
        """
        R√©cup√®re la d√©finition via dictionaryapi.dev (gratuite, sans cl√©)
        Args:
            word: Mot √† chercher
        Returns:
            Dictionnaire avec d√©finition et exemples ou None
        """
        url = f"{self.apis['dictionaryapi']}{word.lower()}"

        try:
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and len(data) > 0:
                    return self.parse_dictionaryapi_response(data[0])

            elif response.status_code == 404:
                logger.debug(f"üîç Mot '{word}' non trouv√© dans l'API")
                return None

            else:
                logger.warning(f"‚ö†Ô∏è Erreur API pour '{word}': {response.status_code}")
                return None

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erreur r√©seau pour '{word}': {e}")
            return None
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur JSON pour '{word}': {e}")
            return None

    def parse_dictionaryapi_response(self, data: dict) -> dict:
        """
        Parse la r√©ponse de dictionaryapi.dev
        Args:
            data: R√©ponse JSON de l'API
        Returns:
            Dictionnaire normalis√©
        """
        word = data.get("word", "")
        phonetic = data.get("phonetic", "")

        definitions = []
        examples = []
        synonyms = []
        antonyms = []

        # Parcourir les significations
        for meaning in data.get("meanings", []):
            part_of_speech = meaning.get("partOfSpeech", "")

            # R√©cup√©rer les d√©finitions
            for definition in meaning.get("definitions", []):
                def_text = definition.get("definition", "")
                if def_text:
                    definitions.append(
                        {
                            "definition": def_text,
                            "part_of_speech": part_of_speech,
                            "example": definition.get("example", ""),
                        }
                    )

                # Exemples
                if definition.get("example"):
                    examples.append(definition["example"])

            # Synonymes et antonymes
            synonyms.extend(meaning.get("synonyms", []))
            antonyms.extend(meaning.get("antonyms", []))

        return {
            "word": word,
            "phonetic": phonetic,
            "definitions": definitions,
            "examples": list(set(examples))[:3],  # Max 3 exemples uniques
            "synonyms": list(set(synonyms))[:5],  # Max 5 synonymes
            "antonyms": list(set(antonyms))[:5],  # Max 5 antonymes
            "source": "dictionaryapi.dev",
        }

    def get_definition(self, word: str) -> dict | None:
        """
        R√©cup√®re la d√©finition d'un mot (avec cache)
        Args:
            word: Mot √† chercher
        Returns:
            Dictionnaire avec d√©finition ou None
        """
        # Normaliser le mot
        clean_word = word.lower().strip()

        # V√©rifier le cache
        if clean_word in self.cache:
            self.stats["cached_definitions"] += 1
            return self.cache[clean_word]

        # D√©lai pour √©viter le rate limiting
        time.sleep(random.uniform(*self.delay_range))

        self.stats["total_requests"] += 1

        # Tenter de r√©cup√©rer la d√©finition
        definition = self.fetch_definition_dictionaryapi(clean_word)

        if definition:
            self.stats["successful_requests"] += 1
            self.cache[clean_word] = definition
            logger.debug(f"‚úÖ D√©finition trouv√©e pour '{word}'")
            return definition
        else:
            self.stats["failed_requests"] += 1
            logger.debug(f"‚ùå Aucune d√©finition pour '{word}'")
            return None

    def process_keywords_file(self, keywords_file: str, context: str) -> list[dict]:
        """
        Traite un fichier de mots-cl√©s et enrichit avec des d√©finitions
        Args:
            keywords_file: Chemin vers le fichier JSON des mots-cl√©s
            context: Contexte (it, work, travel)
        Returns:
            Liste des mots enrichis avec d√©finitions
        """
        logger.info(f"üîç Traitement du fichier: {keywords_file}")

        if not os.path.exists(keywords_file):
            logger.error(f"‚ùå Fichier non trouv√©: {keywords_file}")
            return []

        # Charger les mots-cl√©s
        with open(keywords_file, encoding="utf-8") as f:
            keywords = json.load(f)

        logger.info(f"üìù {len(keywords)} mots-cl√©s √† enrichir pour '{context}'")

        enriched_keywords = []

        for i, keyword in enumerate(keywords):
            word = keyword["word"]

            try:
                # R√©cup√©rer la d√©finition
                definition_data = self.get_definition(word)

                # Cr√©er l'entr√©e enrichie
                enriched_entry = {
                    "word": word,
                    "context": context,
                    "level": keyword["level"],
                    "global_frequency": keyword.get("global_frequency", 0),
                    "importance_score": keyword.get("importance_score", 0),
                    "pos_tags": keyword.get("pos_tags", []),
                    "contexts_from_articles": keyword.get("contexts", []),
                    "source_articles": [
                        {
                            "url": keyword.get("source_url", ""),
                            "title": keyword.get("source_title", ""),
                        }
                    ],
                    "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                }

                # Ajouter les donn√©es de d√©finition si trouv√©es
                if definition_data:
                    enriched_entry.update(
                        {
                            "phonetic": definition_data.get("phonetic", ""),
                            "definitions": definition_data.get("definitions", []),
                            "examples_from_dict": definition_data.get("examples", []),
                            "synonyms": definition_data.get("synonyms", []),
                            "antonyms": definition_data.get("antonyms", []),
                            "dictionary_source": definition_data.get("source", ""),
                            "has_definition": True,
                        }
                    )
                else:
                    enriched_entry.update(
                        {
                            "phonetic": "",
                            "definitions": [],
                            "examples_from_dict": [],
                            "synonyms": [],
                            "antonyms": [],
                            "dictionary_source": "",
                            "has_definition": False,
                        }
                    )

                enriched_keywords.append(enriched_entry)

                # Log de progression
                if (i + 1) % 20 == 0:
                    success_rate = (
                        self.stats["successful_requests"]
                        / max(self.stats["total_requests"], 1)
                    ) * 100
                    logger.info(
                        f"‚úÖ {i + 1}/{len(keywords)} mots trait√©s "
                        f"(succ√®s: {success_rate:.1f}%)"
                    )

            except Exception as e:
                logger.error(f"‚ùå Erreur pour le mot '{word}': {e}")
                continue

        # Statistiques finales
        total_with_def = sum(1 for kw in enriched_keywords if kw["has_definition"])
        success_rate = (
            (total_with_def / len(enriched_keywords)) * 100 if enriched_keywords else 0
        )

        logger.info(f"üéØ {len(enriched_keywords)} mots trait√©s pour '{context}'")
        logger.info(f"üìä {total_with_def} mots avec d√©finition ({success_rate:.1f}%)")

        return enriched_keywords

    def save_definitions(self, definitions: list[dict], output_file: str):
        """Sauvegarde les d√©finitions enrichies"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(definitions, f, ensure_ascii=False, indent=2)

        logger.info(
            f"üíæ {len(definitions)} d√©finitions sauvegard√©es dans {output_file}"
        )

    def print_stats(self):
        """Affiche les statistiques d'utilisation"""
        logger.info("üìä Statistiques des requ√™tes:")
        logger.info(f"   Total: {self.stats['total_requests']}")
        logger.info(f"   Succ√®s: {self.stats['successful_requests']}")
        logger.info(f"   √âchecs: {self.stats['failed_requests']}")
        logger.info(f"   Cache: {self.stats['cached_definitions']}")

        if self.stats["total_requests"] > 0:
            success_rate = (
                self.stats["successful_requests"] / self.stats["total_requests"]
            ) * 100
            logger.info(f"   Taux de succ√®s: {success_rate:.1f}%")


def main():
    """Fonction principale pour tester le r√©cup√©rateur"""
    fetcher = DefinitionFetcher(delay_range=(1.0, 2.0))

    # R√©pertoires
    keywords_dir = "datasets/keywords"
    definitions_dir = "datasets/definitions"
    os.makedirs(definitions_dir, exist_ok=True)

    # Traiter chaque contexte
    contexts = ["it", "work", "travel"]

    for context in contexts:
        keywords_file = f"{keywords_dir}/{context}_keywords.json"

        if os.path.exists(keywords_file):
            logger.info(f"üöÄ R√©cup√©ration des d√©finitions pour '{context}'")

            definitions = fetcher.process_keywords_file(keywords_file, context)

            if definitions:
                output_file = f"{definitions_dir}/{context}_definitions.json"
                fetcher.save_definitions(definitions, output_file)
            else:
                logger.warning(f"‚ö†Ô∏è Aucune d√©finition r√©cup√©r√©e pour '{context}'")
        else:
            logger.warning(f"‚ö†Ô∏è Fichier de mots-cl√©s non trouv√©: {keywords_file}")

    # Afficher les statistiques
    fetcher.print_stats()
    logger.info("üéâ R√©cup√©ration termin√©e pour tous les contextes")


if __name__ == "__main__":
    main()
