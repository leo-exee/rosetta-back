import json
import logging
import os
import random
import re
import time
from urllib.parse import quote

import requests
from bs4 import BeautifulSoup

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FrenchWiktionaryFetcher:
    def __init__(self, delay_range: tuple = (0.5, 2.0)):
        """
        R√©cup√©rateur de d√©finitions depuis Wiktionnaire fran√ßais
        """
        self.delay_range = delay_range
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (compatible; FrenchLearningBot/1.0; Educational purposes)",
                "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
            }
        )

        # URLs de base Wiktionnaire fran√ßais
        self.wiktionary_api = "https://fr.wiktionary.org/api/rest_v1/page/definition/"
        self.wiktionary_web = "https://fr.wiktionary.org/wiki/"

        # Statistiques
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "cached_definitions": 0,
            "api_requests": 0,
            "scrape_requests": 0,
        }

        # Cache pour √©viter les requ√™tes r√©p√©t√©es
        self.cache = {}

    def fetch_definition_wiktionary_api(self, word: str) -> dict | None:
        """
        R√©cup√®re via l'API REST de Wiktionnaire fran√ßais
        """
        url = f"{self.wiktionary_api}{quote(word)}"

        try:
            self.stats["api_requests"] += 1
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                return self.parse_wiktionary_api_response(data, word)
            elif response.status_code == 404:
                logger.debug(f"üîç Mot '{word}' non trouv√© dans l'API Wiktionnaire")
                return None
            else:
                logger.warning(
                    f"‚ö†Ô∏è Erreur API Wiktionnaire pour '{word}': {response.status_code}"
                )
                return None

        except Exception as e:
            logger.error(f"‚ùå Erreur API Wiktionnaire pour '{word}': {e}")
            return None

    def fetch_definition_wiktionary_scrape(self, word: str) -> dict | None:
        """
        R√©cup√®re via scraping de la page Wiktionnaire (fallback)
        """
        url = f"{self.wiktionary_web}{quote(word)}"

        try:
            self.stats["scrape_requests"] += 1
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, "html.parser")
                return self.parse_wiktionary_page(soup, word)
            else:
                return None

        except Exception as e:
            logger.error(f"‚ùå Erreur scraping Wiktionnaire pour '{word}': {e}")
            return None

    def parse_wiktionary_api_response(self, data: dict, word: str) -> dict:
        """Parse la r√©ponse de l'API Wiktionnaire fran√ßais"""
        definitions = []
        examples = []

        # Structure de l'API Wiktionnaire fran√ßaise
        if "fr" in data:
            french_data = data["fr"]

            for definition_entry in french_data:
                part_of_speech = definition_entry.get("partOfSpeech", "")

                if "definitions" in definition_entry:
                    for def_item in definition_entry["definitions"]:
                        definition_text = def_item.get("definition", "")
                        if definition_text:
                            # Nettoyer la d√©finition
                            clean_def = self.clean_french_definition_text(
                                definition_text
                            )

                            definitions.append(
                                {
                                    "definition": clean_def,
                                    "part_of_speech": part_of_speech,
                                    "example": (
                                        def_item.get("examples", [""])[0]
                                        if def_item.get("examples")
                                        else ""
                                    ),
                                }
                            )

                            # Extraire les exemples
                            if def_item.get("examples"):
                                examples.extend(def_item["examples"][:2])

        return {
            "word": word,
            "definitions": definitions[:5],  # Max 5 d√©finitions
            "examples": examples[:3],  # Max 3 exemples
            "source": "wiktionary_api",
            "language": "french",
        }

    def parse_wiktionary_page(self, soup: BeautifulSoup, word: str) -> dict:
        """Parse une page Wiktionnaire fran√ßaise scrap√©e"""
        definitions = []
        examples = []

        # Chercher la section fran√ßaise
        french_section = None
        for h2 in soup.find_all("h2"):
            span = h2.find("span", {"id": "Fran√ßais"})
            if span:
                french_section = h2.parent
                break

        if not french_section:
            # Alternative: chercher directement les sections de d√©finition
            french_section = soup

        # Chercher les d√©finitions dans les listes ordonn√©es
        definition_count = 0
        for ol in french_section.find_all("ol"):
            if definition_count >= 5:  # Limiter √† 5 d√©finitions
                break

            for li in ol.find_all("li"):
                if definition_count >= 5:
                    break

                def_text = li.get_text().strip()
                if def_text and len(def_text) > 10 and not def_text.startswith("("):
                    clean_def = self.clean_french_definition_text(def_text)
                    if len(clean_def) > 5:  # D√©finition valide
                        definitions.append(
                            {
                                "definition": clean_def,
                                "part_of_speech": self.extract_part_of_speech(li),
                                "example": "",
                            }
                        )
                        definition_count += 1

        # Chercher des exemples dans les sections d'exemples
        for em in french_section.find_all("em", limit=3):
            example_text = em.get_text().strip()
            if (
                example_text
                and len(example_text) > 10
                and word.lower() in example_text.lower()
            ):
                examples.append(example_text)

        # Chercher aussi dans les sections avec class="example"
        for example_elem in french_section.find_all(class_="example"):
            example_text = example_elem.get_text().strip()
            if example_text and len(example_text) > 10:
                examples.append(example_text)

        return {
            "word": word,
            "definitions": definitions,
            "examples": examples[:3],
            "source": "wiktionary_scrape",
            "language": "french",
        }

    def extract_part_of_speech(self, li_element) -> str:
        """Extrait la nature grammaticale depuis un √©l√©ment li"""
        # Chercher les abr√©viations grammaticales fran√ßaises courantes
        text = li_element.get_text().lower()

        pos_patterns = {
            "nom": r"\b(nom|n\.)\b",
            "verbe": r"\b(verbe|v\.)\b",
            "adjectif": r"\b(adjectif|adj\.)\b",
            "adverbe": r"\b(adverbe|adv\.)\b",
            "pr√©position": r"\b(pr√©position|pr√©p\.)\b",
            "conjonction": r"\b(conjonction|conj\.)\b",
            "interjection": r"\b(interjection|interj\.)\b",
        }

        for pos, pattern in pos_patterns.items():
            if re.search(pattern, text):
                return pos

        return ""

    def clean_french_definition_text(self, text: str) -> str:
        """Nettoie le texte d'une d√©finition fran√ßaise"""
        # Supprimer les r√©f√©rences et liens
        text = re.sub(r"\[\d+\]", "", text)  # R√©f√©rences [1], [2], etc.
        text = re.sub(r"\([^)]*\)", "", text)  # Texte entre parenth√®ses
        text = re.sub(r"‚Üí voir.*", "", text)  # Liens "voir aussi"
        text = re.sub(r"Voir aussi.*", "", text)  # Liens "voir aussi"

        # Supprimer les balises wiki
        text = re.sub(r"\{\{[^}]*\}\}", "", text)
        text = re.sub(r"\[\[[^\]]*\]\]", "", text)

        # Nettoyer les espaces
        text = re.sub(r"\s+", " ", text).strip()

        # Supprimer les pr√©fixes courants fran√ßais
        prefixes = ["D√©finition:", "Sens:", "‚Ä¢", "-", "*", "1.", "2.", "3."]
        for prefix in prefixes:
            if text.startswith(prefix):
                text = text[len(prefix) :].strip()

        # Supprimer les suffixes de r√©f√©rence
        text = re.sub(r"\s*\([^)]*\)\s*$", "", text)

        return text.strip()

    def get_french_definition(self, word: str) -> dict | None:
        """
        R√©cup√®re la d√©finition d'un mot fran√ßais depuis Wiktionnaire
        """
        clean_word = word.lower().strip()

        # V√©rifier le cache
        if clean_word in self.cache:
            self.stats["cached_definitions"] += 1
            return self.cache[clean_word]

        # D√©lai anti-spam
        time.sleep(random.uniform(*self.delay_range))
        self.stats["total_requests"] += 1

        # Tenter l'API d'abord (plus fiable)
        definition = self.fetch_definition_wiktionary_api(clean_word)

        # Fallback sur le scraping si l'API √©choue ou donne peu de r√©sultats
        if (
            not definition
            or not definition.get("definitions")
            or len(definition["definitions"]) == 0
        ):
            logger.debug(f"üîÑ Fallback scraping pour '{word}'")
            definition = self.fetch_definition_wiktionary_scrape(clean_word)

        if (
            definition
            and definition.get("definitions")
            and len(definition["definitions"]) > 0
        ):
            self.stats["successful_requests"] += 1
            self.cache[clean_word] = definition
            logger.debug(
                f"‚úÖ D√©finition fran√ßaise trouv√©e pour '{word}' ({len(definition['definitions'])} d√©finitions)"
            )
            return definition
        else:
            self.stats["failed_requests"] += 1
            logger.debug(f"‚ùå Aucune d√©finition fran√ßaise pour '{word}'")
            return None

    def process_french_keywords_file(
        self, keywords_file: str, context: str
    ) -> list[dict]:
        """
        Traite un fichier de mots-cl√©s fran√ßais et enrichit avec Wiktionnaire
        """
        logger.info(f"üá´üá∑ Traitement du fichier de mots-cl√©s fran√ßais: {keywords_file}")

        if not os.path.exists(keywords_file):
            logger.error(f"‚ùå Fichier non trouv√©: {keywords_file}")
            return []

        with open(keywords_file, encoding="utf-8") as f:
            keywords = json.load(f)

        logger.info(
            f"üìù {len(keywords)} mots-cl√©s fran√ßais √† enrichir pour '{context}'"
        )

        enriched_keywords = []

        for i, keyword in enumerate(keywords):
            word = keyword["word"]

            try:
                # R√©cup√©rer depuis Wiktionnaire fran√ßais
                definition_data = self.get_french_definition(word)

                enriched_entry = {
                    "word": word,
                    "context": context,
                    "level": keyword["level"],
                    "global_frequency": keyword.get("global_frequency", 0),
                    "importance_score": keyword.get("importance_score", 0),
                    "pos_tags": keyword.get("pos_tags", []),
                    "contexts_from_articles": keyword.get("contexts", []),
                    "source_articles": [
                        {
                            "url": keyword.get("source_url", ""),
                            "title": keyword.get("source_title", ""),
                        }
                    ],
                    "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "language": "french",
                }

                if definition_data:
                    enriched_entry.update(
                        {
                            "definitions": definition_data.get("definitions", []),
                            "examples_from_dict": definition_data.get("examples", []),
                            "dictionary_source": definition_data.get("source", ""),
                            "has_definition": True,
                            "definition_count": len(
                                definition_data.get("definitions", [])
                            ),
                        }
                    )
                else:
                    enriched_entry.update(
                        {
                            "definitions": [],
                            "examples_from_dict": [],
                            "dictionary_source": "",
                            "has_definition": False,
                            "definition_count": 0,
                        }
                    )

                enriched_keywords.append(enriched_entry)

                # Log de progression
                if (i + 1) % 10 == 0:
                    success_rate = (
                        self.stats["successful_requests"]
                        / max(self.stats["total_requests"], 1)
                    ) * 100
                    logger.info(
                        f"‚úÖ {i + 1}/{len(keywords)} mots fran√ßais trait√©s "
                        f"(succ√®s: {success_rate:.1f}%)"
                    )

            except Exception as e:
                logger.error(f"‚ùå Erreur pour le mot fran√ßais '{word}': {e}")
                continue

        # Statistiques finales
        total_with_def = sum(1 for kw in enriched_keywords if kw["has_definition"])
        success_rate = (
            (total_with_def / len(enriched_keywords)) * 100 if enriched_keywords else 0
        )

        logger.info(
            f"üéØ {len(enriched_keywords)} mots fran√ßais trait√©s pour '{context}'"
        )
        logger.info(
            f"üìä {total_with_def} mots avec d√©finition Wiktionnaire ({success_rate:.1f}%)"
        )

        return enriched_keywords

    def save_french_definitions(self, definitions: list[dict], output_file: str):
        """Sauvegarde les d√©finitions fran√ßaises enrichies"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(definitions, f, ensure_ascii=False, indent=2)

        logger.info(
            f"üíæ {len(definitions)} d√©finitions fran√ßaises sauvegard√©es dans {output_file}"
        )

    def print_french_stats(self):
        """Affiche les statistiques d√©taill√©es Wiktionnaire fran√ßais"""
        logger.info("üìä Statistiques Wiktionnaire fran√ßais:")
        logger.info(f"   Total requ√™tes: {self.stats['total_requests']}")
        logger.info(f"   Succ√®s: {self.stats['successful_requests']}")
        logger.info(f"   √âchecs: {self.stats['failed_requests']}")
        logger.info(f"   Cache utilis√©: {self.stats['cached_definitions']}")
        logger.info(f"   Requ√™tes API: {self.stats['api_requests']}")
        logger.info(f"   Requ√™tes scraping: {self.stats['scrape_requests']}")

        if self.stats["total_requests"] > 0:
            success_rate = (
                self.stats["successful_requests"] / self.stats["total_requests"]
            ) * 100
            logger.info(f"   Taux de succ√®s global: {success_rate:.1f}%")


def main():
    """Test du service Wiktionnaire fran√ßais"""
    fetcher = FrenchWiktionaryFetcher(delay_range=(1.0, 2.0))

    # R√©pertoires fran√ßais
    keywords_dir = "datasets/keywords_fr"
    definitions_dir = "datasets/definitions_fr"
    os.makedirs(definitions_dir, exist_ok=True)

    # Traiter chaque contexte fran√ßais
    contexts = ["it", "work", "travel", "cooking"]

    for context in contexts:
        keywords_file = f"{keywords_dir}/{context}_keywords_fr.json"

        if os.path.exists(keywords_file):
            logger.info(f"üöÄ R√©cup√©ration des d√©finitions fran√ßaises pour '{context}'")

            definitions = fetcher.process_french_keywords_file(keywords_file, context)

            if definitions:
                output_file = f"{definitions_dir}/{context}_definitions_fr.json"
                fetcher.save_french_definitions(definitions, output_file)
            else:
                logger.warning(
                    f"‚ö†Ô∏è Aucune d√©finition fran√ßaise r√©cup√©r√©e pour '{context}'"
                )
        else:
            logger.warning(
                f"‚ö†Ô∏è Fichier de mots-cl√©s fran√ßais non trouv√©: {keywords_file}"
            )

    # Afficher les statistiques
    fetcher.print_french_stats()
    logger.info("üéâ R√©cup√©ration fran√ßaise termin√©e pour tous les contextes")


if __name__ == "__main__":
    main()
